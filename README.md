
---

```markdown
# ğŸ¤– Content Generation Agent

A scalable FastAPI-based multi-agent AI backend built using LangChain and LLM pipelines.  
This project processes user queries through structured agent workflows and returns refined responses.

---

## ğŸš€ Features

- âš¡ Async FastAPI backend
- ğŸ§  Multi-agent pipeline architecture
- ğŸ” Review & refinement agent
- ğŸŒ SERP API integration
- ğŸ” Environment-based configuration
- ğŸ“¦ uv for dependency management
- ğŸ“˜ Auto-generated Swagger documentation

---

## ğŸ— Architecture

User Query  
â†“  
Primary Agent  
â†“  
Review Agent  
â†“  
Final Response  

The system is modular and designed for scalability.

---

## ğŸ›  Tech Stack

- Python 3.11+
- FastAPI
- LangChain
- Pydantic
- Uvicorn
- uv (dependency manager)

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/harsharora05/content-generation-agent.git
cd content-generation-agent
```

### 2ï¸âƒ£ Install dependencies (using uv)

```bash
uv sync
```

---

## ğŸ” Environment Variables

Create a `.env` file in the project root:

```
OPENAI_API_KEY=your_openai_key
SERPAPI_KEY=your_serpapi_key
```

âš ï¸ Do NOT commit your `.env` file.  
Use a `.env.example` file for sharing environment structure.

---

## â–¶ï¸ Run the Application

```bash
uv run main.py
```

Server will start at:

```
http://127.0.0.1:8000
```

Swagger Documentation:

```
http://127.0.0.1:8000/docs
```

---

## ğŸ“¡ API Endpoint

### POST `/generate`

### Request Body

```json
{
  "query": "What is 2 + 2?"
}
```

### Response

```json
{
  "success": true,
  "response": "4"
}
```
